{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OnlineNewsPopularity dataset\n",
    "[Source](https://www.openml.org/search?type=data&sort=qualities.NumberOfFeatures&status=active&qualities.NumberOfClasses=lte_1&qualities.NumberOfFeatures=between_10_100&format=ARFF&qualities.NumberOfInstances=between_1000_10000&id=4545)\n",
    "\n",
    "Goal: predict the number of shares in social networks (popularity).\n",
    "\n",
    "Perfect challenge for a random forest tree regressor.\n",
    "\n",
    "39644 instances\n",
    "\n",
    "61 features\n",
    "\n",
    "Each instance is an article publication and all features are different characteristics of the articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io.arff import loadarff \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import sklearn\n",
    "from random_forest_regressor import RandomForestRegressor\n",
    "import sklearn.ensemble\n",
    "import time\n",
    "\n",
    "RANDOM_SEED = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = loadarff('phpgBMvy4.arff')\n",
    "df = pd.DataFrame(raw_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'http://mashable.com/2013/01/07/amazon-instan...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>593.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'http://mashable.com/2013/01/07/ap-samsung-sp...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>711.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'http://mashable.com/2013/01/07/apple-40-bill...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'http://mashable.com/2013/01/07/astronaut-not...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'http://mashable.com/2013/01/07/att-u-verse-a...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>505.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  timedelta  \\\n",
       "0  b'http://mashable.com/2013/01/07/amazon-instan...      731.0   \n",
       "1  b'http://mashable.com/2013/01/07/ap-samsung-sp...      731.0   \n",
       "2  b'http://mashable.com/2013/01/07/apple-40-bill...      731.0   \n",
       "3  b'http://mashable.com/2013/01/07/astronaut-not...      731.0   \n",
       "4  b'http://mashable.com/2013/01/07/att-u-verse-a...      731.0   \n",
       "\n",
       "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0            12.0             219.0         0.663594               1.0   \n",
       "1             9.0             255.0         0.604743               1.0   \n",
       "2             9.0             211.0         0.575130               1.0   \n",
       "3             9.0             531.0         0.503788               1.0   \n",
       "4            13.0            1072.0         0.415646               1.0   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  ...  \\\n",
       "0                  0.815385        4.0             2.0       1.0  ...   \n",
       "1                  0.791946        3.0             1.0       1.0  ...   \n",
       "2                  0.663866        3.0             1.0       1.0  ...   \n",
       "3                  0.665635        9.0             0.0       1.0  ...   \n",
       "4                  0.540890       19.0            19.0      20.0  ...   \n",
       "\n",
       "   min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
       "0               0.100000                    0.7              -0.350000   \n",
       "1               0.033333                    0.7              -0.118750   \n",
       "2               0.100000                    1.0              -0.466667   \n",
       "3               0.136364                    0.8              -0.369697   \n",
       "4               0.033333                    1.0              -0.220192   \n",
       "\n",
       "   min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "0                 -0.600              -0.200000            0.500000   \n",
       "1                 -0.125              -0.100000            0.000000   \n",
       "2                 -0.800              -0.133333            0.000000   \n",
       "3                 -0.600              -0.166667            0.000000   \n",
       "4                 -0.500              -0.050000            0.454545   \n",
       "\n",
       "   title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0                 -0.187500                0.000000   \n",
       "1                  0.000000                0.500000   \n",
       "2                  0.000000                0.500000   \n",
       "3                  0.000000                0.500000   \n",
       "4                  0.136364                0.045455   \n",
       "\n",
       "   abs_title_sentiment_polarity  shares  \n",
       "0                      0.187500   593.0  \n",
       "1                      0.000000   711.0  \n",
       "2                      0.000000  1500.0  \n",
       "3                      0.000000  1200.0  \n",
       "4                      0.136364   505.0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape # (39644\t61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39644 entries, 0 to 39643\n",
      "Data columns (total 61 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   url                            39644 non-null  object \n",
      " 1   timedelta                      39644 non-null  float64\n",
      " 2   n_tokens_title                 39644 non-null  float64\n",
      " 3   n_tokens_content               39644 non-null  float64\n",
      " 4   n_unique_tokens                39644 non-null  float64\n",
      " 5   n_non_stop_words               39644 non-null  float64\n",
      " 6   n_non_stop_unique_tokens       39644 non-null  float64\n",
      " 7   num_hrefs                      39644 non-null  float64\n",
      " 8   num_self_hrefs                 39644 non-null  float64\n",
      " 9   num_imgs                       39644 non-null  float64\n",
      " 10  num_videos                     39644 non-null  float64\n",
      " 11  average_token_length           39644 non-null  float64\n",
      " 12  num_keywords                   39644 non-null  float64\n",
      " 13  data_channel_is_lifestyle      39644 non-null  float64\n",
      " 14  data_channel_is_entertainment  39644 non-null  float64\n",
      " 15  data_channel_is_bus            39644 non-null  float64\n",
      " 16  data_channel_is_socmed         39644 non-null  float64\n",
      " 17  data_channel_is_tech           39644 non-null  float64\n",
      " 18  data_channel_is_world          39644 non-null  float64\n",
      " 19  kw_min_min                     39644 non-null  float64\n",
      " 20  kw_max_min                     39644 non-null  float64\n",
      " 21  kw_avg_min                     39644 non-null  float64\n",
      " 22  kw_min_max                     39644 non-null  float64\n",
      " 23  kw_max_max                     39644 non-null  float64\n",
      " 24  kw_avg_max                     39644 non-null  float64\n",
      " 25  kw_min_avg                     39644 non-null  float64\n",
      " 26  kw_max_avg                     39644 non-null  float64\n",
      " 27  kw_avg_avg                     39644 non-null  float64\n",
      " 28  self_reference_min_shares      39644 non-null  float64\n",
      " 29  self_reference_max_shares      39644 non-null  float64\n",
      " 30  self_reference_avg_sharess     39644 non-null  float64\n",
      " 31  weekday_is_monday              39644 non-null  float64\n",
      " 32  weekday_is_tuesday             39644 non-null  float64\n",
      " 33  weekday_is_wednesday           39644 non-null  float64\n",
      " 34  weekday_is_thursday            39644 non-null  float64\n",
      " 35  weekday_is_friday              39644 non-null  float64\n",
      " 36  weekday_is_saturday            39644 non-null  float64\n",
      " 37  weekday_is_sunday              39644 non-null  float64\n",
      " 38  is_weekend                     39644 non-null  float64\n",
      " 39  LDA_00                         39644 non-null  float64\n",
      " 40  LDA_01                         39644 non-null  float64\n",
      " 41  LDA_02                         39644 non-null  float64\n",
      " 42  LDA_03                         39644 non-null  float64\n",
      " 43  LDA_04                         39644 non-null  float64\n",
      " 44  global_subjectivity            39644 non-null  float64\n",
      " 45  global_sentiment_polarity      39644 non-null  float64\n",
      " 46  global_rate_positive_words     39644 non-null  float64\n",
      " 47  global_rate_negative_words     39644 non-null  float64\n",
      " 48  rate_positive_words            39644 non-null  float64\n",
      " 49  rate_negative_words            39644 non-null  float64\n",
      " 50  avg_positive_polarity          39644 non-null  float64\n",
      " 51  min_positive_polarity          39644 non-null  float64\n",
      " 52  max_positive_polarity          39644 non-null  float64\n",
      " 53  avg_negative_polarity          39644 non-null  float64\n",
      " 54  min_negative_polarity          39644 non-null  float64\n",
      " 55  max_negative_polarity          39644 non-null  float64\n",
      " 56  title_subjectivity             39644 non-null  float64\n",
      " 57  title_sentiment_polarity       39644 non-null  float64\n",
      " 58  abs_title_subjectivity         39644 non-null  float64\n",
      " 59  abs_title_sentiment_polarity   39644 non-null  float64\n",
      " 60  shares                         39644 non-null  float64\n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 18.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the description of the variables, we will drop \"url\", since it works as an ID, and also drop \"timedelta\", since it represents days between the article publication and the dataset acquisition (non-predictive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"url\", \"timedelta\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.680365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>593.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.913725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>711.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.393365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.404896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.682836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>505.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0            12.0             219.0         0.663594               1.0   \n",
       "1             9.0             255.0         0.604743               1.0   \n",
       "2             9.0             211.0         0.575130               1.0   \n",
       "3             9.0             531.0         0.503788               1.0   \n",
       "4            13.0            1072.0         0.415646               1.0   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  num_videos  \\\n",
       "0                  0.815385        4.0             2.0       1.0         0.0   \n",
       "1                  0.791946        3.0             1.0       1.0         0.0   \n",
       "2                  0.663866        3.0             1.0       1.0         0.0   \n",
       "3                  0.665635        9.0             0.0       1.0         0.0   \n",
       "4                  0.540890       19.0            19.0      20.0         0.0   \n",
       "\n",
       "   average_token_length  ...  min_positive_polarity  max_positive_polarity  \\\n",
       "0              4.680365  ...               0.100000                    0.7   \n",
       "1              4.913725  ...               0.033333                    0.7   \n",
       "2              4.393365  ...               0.100000                    1.0   \n",
       "3              4.404896  ...               0.136364                    0.8   \n",
       "4              4.682836  ...               0.033333                    1.0   \n",
       "\n",
       "   avg_negative_polarity  min_negative_polarity  max_negative_polarity  \\\n",
       "0              -0.350000                 -0.600              -0.200000   \n",
       "1              -0.118750                 -0.125              -0.100000   \n",
       "2              -0.466667                 -0.800              -0.133333   \n",
       "3              -0.369697                 -0.600              -0.166667   \n",
       "4              -0.220192                 -0.500              -0.050000   \n",
       "\n",
       "   title_subjectivity  title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0            0.500000                 -0.187500                0.000000   \n",
       "1            0.000000                  0.000000                0.500000   \n",
       "2            0.000000                  0.000000                0.500000   \n",
       "3            0.000000                  0.000000                0.500000   \n",
       "4            0.454545                  0.136364                0.045455   \n",
       "\n",
       "   abs_title_sentiment_polarity  shares  \n",
       "0                      0.187500   593.0  \n",
       "1                      0.000000   711.0  \n",
       "2                      0.000000  1500.0  \n",
       "3                      0.000000  1200.0  \n",
       "4                      0.136364   505.0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = df.drop(\"shares\", axis=1)\n",
    "y_data = df[\"shares\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the experiments\n",
    "\n",
    "### Baseline experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_implementation = time.time()\n",
    "rf = RandomForestRegressor(n_trees=5, max_features=1, min_samples_split=2, max_depth=5)\n",
    "rf.train(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "end_time_implementation = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_sk = time.time()\n",
    "sklearn_rf = sklearn.ensemble.RandomForestRegressor(n_estimators=5, max_depth=5, random_state=RANDOM_SEED)\n",
    "sklearn_rf.fit(X_train, y_train)\n",
    "sk_y_pred = sklearn_rf.predict(X_test)\n",
    "end_time_sk = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of implementation:  10985.340310784997\n",
      "RMSE of sklearn:  12049.228010015688\n",
      "Runtime of implementation 617.0055634975433\n",
      "Runtime of sklearn 1.4171433448791504\n"
     ]
    }
   ],
   "source": [
    "implementation_rmse = root_mean_squared_error(y_test, y_pred)\n",
    "sklearn_rmse = root_mean_squared_error(y_test, sk_y_pred)\n",
    "print(\"RMSE of implementation: \", implementation_rmse)\n",
    "print(\"RMSE of sklearn: \", sklearn_rmse)\n",
    "implementation_runtime = end_time_implementation - start_time_implementation\n",
    "sklearn_runtime = end_time_sk - start_time_sk\n",
    "print(\"Runtime of implementation\", implementation_runtime)\n",
    "print(\"Runtime of sklearn\", sklearn_runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments on trees depth\n",
    "**1. Decrease tree depth to 2 instead of 5** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_implementation = time.time()\n",
    "rf = RandomForestRegressor(n_trees=5, max_features=1, min_samples_split=2, max_depth=2)\n",
    "rf.train(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "end_time_implementation = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_sk = time.time()\n",
    "sklearn_rf = sklearn.ensemble.RandomForestRegressor(n_estimators=5, max_depth=2, random_state=RANDOM_SEED)\n",
    "sklearn_rf.fit(X_train, y_train)\n",
    "sk_y_pred = sklearn_rf.predict(X_test)\n",
    "end_time_sk = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of implementation:  10987.116007862305\n",
      "RMSE of sklearn:  10821.73138056426\n",
      "Runtime of implementation 292.96818494796753\n",
      "Runtime of sklearn 0.5936460494995117\n"
     ]
    }
   ],
   "source": [
    "implementation_rmse = root_mean_squared_error(y_test, y_pred)\n",
    "sklearn_rmse = root_mean_squared_error(y_test, sk_y_pred)\n",
    "print(\"RMSE of implementation: \", implementation_rmse)\n",
    "print(\"RMSE of sklearn: \", sklearn_rmse)\n",
    "implementation_runtime = end_time_implementation - start_time_implementation\n",
    "sklearn_runtime = end_time_sk - start_time_sk\n",
    "print(\"Runtime of implementation\", implementation_runtime)\n",
    "print(\"Runtime of sklearn\", sklearn_runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Increase tree depth to None instead of 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m start_time_implementation \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      2\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_trees\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      5\u001b[0m end_time_implementation \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\marga\\Desktop\\Faculdade\\ML\\git\\MachineLearningCourse\\Exercise2\\random_forest_regressor.py:36\u001b[0m, in \u001b[0;36mRandomForestRegressor.train\u001b[1;34m(self, X_data, y_data)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_tress):\n\u001b[0;32m     35\u001b[0m     tree \u001b[38;5;241m=\u001b[39m regressor_tree\u001b[38;5;241m.\u001b[39mNode(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_features, min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_split, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth)\n\u001b[1;32m---> 36\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitted_trees\u001b[38;5;241m.\u001b[39mappend(tree)\n",
      "File \u001b[1;32mc:\\Users\\marga\\Desktop\\Faculdade\\ML\\git\\MachineLearningCourse\\Exercise2\\regressor_tree.py:121\u001b[0m, in \u001b[0;36mNode.train\u001b[1;34m(self, X_data, y_data)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_child \u001b[38;5;241m=\u001b[39m Node(height\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_features, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth, min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_split)\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_child \u001b[38;5;241m=\u001b[39m Node(height\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_features, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth, min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_split)\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft_child\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_left_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_left_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_child\u001b[38;5;241m.\u001b[39mtrain(data_right_X, data_right_y)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;66;03m# Get the prediction value by the mean of the remaining target data (y_data)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\marga\\Desktop\\Faculdade\\ML\\git\\MachineLearningCourse\\Exercise2\\regressor_tree.py:121\u001b[0m, in \u001b[0;36mNode.train\u001b[1;34m(self, X_data, y_data)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_child \u001b[38;5;241m=\u001b[39m Node(height\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_features, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth, min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_split)\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_child \u001b[38;5;241m=\u001b[39m Node(height\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_features, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth, min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_split)\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft_child\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_left_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_left_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_child\u001b[38;5;241m.\u001b[39mtrain(data_right_X, data_right_y)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;66;03m# Get the prediction value by the mean of the remaining target data (y_data)\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: Node.train at line 121 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\marga\\Desktop\\Faculdade\\ML\\git\\MachineLearningCourse\\Exercise2\\regressor_tree.py:122\u001b[0m, in \u001b[0;36mNode.train\u001b[1;34m(self, X_data, y_data)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_child \u001b[38;5;241m=\u001b[39m Node(height\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_features, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth, min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_split)\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_child\u001b[38;5;241m.\u001b[39mtrain(data_left_X, data_left_y)\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright_child\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_right_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_right_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;66;03m# Get the prediction value by the mean of the remaining target data (y_data)\u001b[39;00m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_data\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32mc:\\Users\\marga\\Desktop\\Faculdade\\ML\\git\\MachineLearningCourse\\Exercise2\\regressor_tree.py:122\u001b[0m, in \u001b[0;36mNode.train\u001b[1;34m(self, X_data, y_data)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_child \u001b[38;5;241m=\u001b[39m Node(height\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_features, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth, min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_split)\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_child\u001b[38;5;241m.\u001b[39mtrain(data_left_X, data_left_y)\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright_child\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_right_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_right_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;66;03m# Get the prediction value by the mean of the remaining target data (y_data)\u001b[39;00m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_data\u001b[38;5;241m.\u001b[39mmean()\n",
      "    \u001b[1;31m[... skipping similar frames: Node.train at line 121 (7 times), Node.train at line 122 (5 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\marga\\Desktop\\Faculdade\\ML\\git\\MachineLearningCourse\\Exercise2\\regressor_tree.py:122\u001b[0m, in \u001b[0;36mNode.train\u001b[1;34m(self, X_data, y_data)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_child \u001b[38;5;241m=\u001b[39m Node(height\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_features, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth, min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_split)\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_child\u001b[38;5;241m.\u001b[39mtrain(data_left_X, data_left_y)\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright_child\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_right_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_right_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;66;03m# Get the prediction value by the mean of the remaining target data (y_data)\u001b[39;00m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_data\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32mc:\\Users\\marga\\Desktop\\Faculdade\\ML\\git\\MachineLearningCourse\\Exercise2\\regressor_tree.py:121\u001b[0m, in \u001b[0;36mNode.train\u001b[1;34m(self, X_data, y_data)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_child \u001b[38;5;241m=\u001b[39m Node(height\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_features, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth, min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_split)\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_child \u001b[38;5;241m=\u001b[39m Node(height\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_features, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth, min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples_split)\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft_child\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_left_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_left_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_child\u001b[38;5;241m.\u001b[39mtrain(data_right_X, data_right_y)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;66;03m# Get the prediction value by the mean of the remaining target data (y_data)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\marga\\Desktop\\Faculdade\\ML\\git\\MachineLearningCourse\\Exercise2\\regressor_tree.py:107\u001b[0m, in \u001b[0;36mNode.train\u001b[1;34m(self, X_data, y_data)\u001b[0m\n\u001b[0;32m    105\u001b[0m dict_averages_per_feature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_average_values_per_feature()\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Insert split value for current node\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_feature, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_optimal_split_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdict_averages_per_feature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# Split data according to split value\u001b[39;00m\n\u001b[0;32m    111\u001b[0m data_left_X  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_feature] \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_value]\n",
      "File \u001b[1;32mc:\\Users\\marga\\Desktop\\Faculdade\\ML\\git\\MachineLearningCourse\\Exercise2\\regressor_tree.py:51\u001b[0m, in \u001b[0;36mNode.get_optimal_split_value\u001b[1;34m(self, dict_averages_per_feature)\u001b[0m\n\u001b[0;32m     48\u001b[0m right_mean_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrepeat(right_target_mean, \u001b[38;5;28mlen\u001b[39m(right_df))\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# calculate individual SSR (Sum Squared Residuals)\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m left_ssr  \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msquare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_df\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mleft_mean_array\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     52\u001b[0m right_ssr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39msquare(right_df \u001b[38;5;241m-\u001b[39m right_mean_array))\n\u001b[0;32m     54\u001b[0m total_ssr \u001b[38;5;241m=\u001b[39m left_ssr \u001b[38;5;241m+\u001b[39m right_ssr\n",
      "File \u001b[1;32mc:\\Users\\marga\\Desktop\\Faculdade\\ML\\git\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:2171\u001b[0m, in \u001b[0;36mNDFrame.__array_ufunc__\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2167\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   2168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array_ufunc__\u001b[39m(\n\u001b[0;32m   2169\u001b[0m     \u001b[38;5;28mself\u001b[39m, ufunc: np\u001b[38;5;241m.\u001b[39mufunc, method: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39minputs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m   2170\u001b[0m ):\n\u001b[1;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marraylike\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_ufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mufunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marga\\Desktop\\Faculdade\\ML\\git\\.venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:414\u001b[0m, in \u001b[0;36marray_ufunc\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    411\u001b[0m         result \u001b[38;5;241m=\u001b[39m default_array_ufunc(inputs[\u001b[38;5;241m0\u001b[39m], ufunc, method, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    412\u001b[0m         \u001b[38;5;66;03m# e.g. np.negative (only one reached), with \"where\" and \"out\" in kwargs\u001b[39;00m\n\u001b[1;32m--> 414\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mreconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\marga\\Desktop\\Faculdade\\ML\\git\\.venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:343\u001b[0m, in \u001b[0;36marray_ufunc.<locals>.reconstruct\u001b[1;34m(result)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mnout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;66;03m# np.modf, np.frexp, np.divmod\u001b[39;00m\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(_reconstruct(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[1;32m--> 343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marga\\Desktop\\Faculdade\\ML\\git\\.venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:358\u001b[0m, in \u001b[0;36marray_ufunc.<locals>._reconstruct\u001b[1;34m(result)\u001b[0m\n\u001b[0;32m    355\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(result, axes\u001b[38;5;241m=\u001b[39mresult\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;66;03m# we converted an array, lost our axes\u001b[39;00m\n\u001b[1;32m--> 358\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constructor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mreconstruct_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mreconstruct_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;66;03m# TODO: When we support multiple values in __finalize__, this\u001b[39;00m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;66;03m# should pass alignable to `__finalize__` instead of self.\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;66;03m# Then `np.add(a, b)` would consider attrs from both a and b\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;66;03m# when a and b are NDFrames.\u001b[39;00m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(alignable) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\marga\\Desktop\\Faculdade\\ML\\git\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:584\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    582\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    586\u001b[0m     manager \u001b[38;5;241m=\u001b[39m _get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\marga\\Desktop\\Faculdade\\ML\\git\\.venv\\Lib\\site-packages\\pandas\\core\\construction.py:664\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(subarr, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    662\u001b[0m     \u001b[38;5;66;03m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[39;00m\n\u001b[0;32m    663\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mdtype, dtype)\n\u001b[1;32m--> 664\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m \u001b[43m_sanitize_str_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m subarr\n",
      "File \u001b[1;32mc:\\Users\\marga\\Desktop\\Faculdade\\ML\\git\\.venv\\Lib\\site-packages\\pandas\\core\\construction.py:735\u001b[0m, in \u001b[0;36m_sanitize_str_dtypes\u001b[1;34m(result, data, dtype, copy)\u001b[0m\n\u001b[0;32m    731\u001b[0m             result \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39masarray_tuplesafe(data, dtype\u001b[38;5;241m=\u001b[39mdtype)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m--> 735\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sanitize_str_dtypes\u001b[39m(\n\u001b[0;32m    736\u001b[0m     result: np\u001b[38;5;241m.\u001b[39mndarray, data, dtype: np\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, copy: \u001b[38;5;28mbool\u001b[39m\n\u001b[0;32m    737\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m    738\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;124;03m    Ensure we have a dtype that is supported by pandas.\u001b[39;00m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# This is to prevent mixed-type Series getting all casted to\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# NumPy string type, e.g. NaN --> '-1#IND'.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time_implementation = time.time()\n",
    "rf = RandomForestRegressor(n_trees=5, max_features=1, min_samples_split=2, max_depth=None)\n",
    "rf.train(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "end_time_implementation = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.getrecursionlimit())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By printing the recursion limit, we can see that our implementation exceeded 3000 recursions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_sk = time.time()\n",
    "sklearn_rf = sklearn.ensemble.RandomForestRegressor(n_estimators=5, max_depth=None, random_state=RANDOM_SEED)\n",
    "sklearn_rf.fit(X_train, y_train)\n",
    "sk_y_pred = sklearn_rf.predict(X_test)\n",
    "end_time_sk = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of sklearn:  0.2814079075177691\n",
      "Runtime of sklearn 0.3791069984436035\n"
     ]
    }
   ],
   "source": [
    "#implementation_rmse = root_mean_squared_error(y_test, y_pred)\n",
    "sklearn_rmse = root_mean_squared_error(y_test, sk_y_pred)\n",
    "#print(\"RMSE of implementation: \", implementation_rmse)\n",
    "print(\"RMSE of sklearn: \", sklearn_rmse)\n",
    "#implementation_runtime = end_time_implementation - start_time_implementation\n",
    "sklearn_runtime = end_time_sk - start_time_sk\n",
    "#print(\"Runtime of implementation\", implementation_runtime)\n",
    "print(\"Runtime of sklearn\", sklearn_runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Increase tree depth to 20 instead of 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_implementation = time.time()\n",
    "rf = RandomForestRegressor(n_trees=5, max_features=1, min_samples_split=2, max_depth=20)\n",
    "rf.train(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "end_time_implementation = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_sk = time.time()\n",
    "sklearn_rf = sklearn.ensemble.RandomForestRegressor(n_estimators=5, max_depth=20, random_state=RANDOM_SEED)\n",
    "sklearn_rf.fit(X_train, y_train)\n",
    "sk_y_pred = sklearn_rf.predict(X_test)\n",
    "end_time_sk = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of implementation:  0.23957197065958202\n",
      "RMSE of sklearn:  0.27971263323518153\n",
      "Runtime of implementation 118.94622135162354\n",
      "Runtime of sklearn 0.39827799797058105\n"
     ]
    }
   ],
   "source": [
    "implementation_rmse = root_mean_squared_error(y_test, y_pred)\n",
    "sklearn_rmse = root_mean_squared_error(y_test, sk_y_pred)\n",
    "print(\"RMSE of implementation: \", implementation_rmse)\n",
    "print(\"RMSE of sklearn: \", sklearn_rmse)\n",
    "implementation_runtime = end_time_implementation - start_time_implementation\n",
    "sklearn_runtime = end_time_sk - start_time_sk\n",
    "print(\"Runtime of implementation\", implementation_runtime)\n",
    "print(\"Runtime of sklearn\", sklearn_runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments on max features\n",
    "**1. Increase max features to 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_implementation = time.time()\n",
    "rf = RandomForestRegressor(n_trees=5, max_features=2, min_samples_split=2, max_depth=5)\n",
    "rf.train(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "end_time_implementation = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_sk = time.time()\n",
    "sklearn_rf = sklearn.ensemble.RandomForestRegressor(n_estimators=5, max_depth=5, max_features=2, random_state=RANDOM_SEED)\n",
    "sklearn_rf.fit(X_train, y_train)\n",
    "sk_y_pred = sklearn_rf.predict(X_test)\n",
    "end_time_sk = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of implementation:  0.23957197065958202\n",
      "RMSE of sklearn:  0.23570879464546549\n",
      "Runtime of implementation 118.94622135162354\n",
      "Runtime of sklearn 0.03200674057006836\n"
     ]
    }
   ],
   "source": [
    "implementation_rmse = root_mean_squared_error(y_test, y_pred)\n",
    "sklearn_rmse = root_mean_squared_error(y_test, sk_y_pred)\n",
    "print(\"RMSE of implementation: \", implementation_rmse)\n",
    "print(\"RMSE of sklearn: \", sklearn_rmse)\n",
    "implementation_runtime = end_time_implementation - start_time_implementation\n",
    "sklearn_runtime = end_time_sk - start_time_sk\n",
    "print(\"Runtime of implementation\", implementation_runtime)\n",
    "print(\"Runtime of sklearn\", sklearn_runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Increase max features to 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_implementation = time.time()\n",
    "rf = RandomForestRegressor(n_trees=5, max_features=5, min_samples_split=2, max_depth=5)\n",
    "rf.train(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "end_time_implementation = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_sk = time.time()\n",
    "sklearn_rf = sklearn.ensemble.RandomForestRegressor(n_estimators=5, max_depth=5, max_features=5,random_state=RANDOM_SEED)\n",
    "sklearn_rf.fit(X_train, y_train)\n",
    "sk_y_pred = sklearn_rf.predict(X_test)\n",
    "end_time_sk = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of implementation:  0.23957197065958202\n",
      "RMSE of sklearn:  0.2355863726400265\n",
      "Runtime of implementation 118.94622135162354\n",
      "Runtime of sklearn 0.04115128517150879\n"
     ]
    }
   ],
   "source": [
    "implementation_rmse = root_mean_squared_error(y_test, y_pred)\n",
    "sklearn_rmse = root_mean_squared_error(y_test, sk_y_pred)\n",
    "print(\"RMSE of implementation: \", implementation_rmse)\n",
    "print(\"RMSE of sklearn: \", sklearn_rmse)\n",
    "implementation_runtime = end_time_implementation - start_time_implementation\n",
    "sklearn_runtime = end_time_sk - start_time_sk\n",
    "print(\"Runtime of implementation\", implementation_runtime)\n",
    "print(\"Runtime of sklearn\", sklearn_runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments on min samples splits\n",
    "**1. Increase min_sample_split to 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_implementation = time.time()\n",
    "rf = RandomForestRegressor(n_trees=5, max_features=1, min_samples_split=5, max_depth=5)\n",
    "rf.train(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "end_time_implementation = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_sk = time.time()\n",
    "sklearn_rf = sklearn.ensemble.RandomForestRegressor(n_estimators=5, max_depth=5, max_features=1, min_samples_split=5, random_state=RANDOM_SEED)\n",
    "sklearn_rf.fit(X_train, y_train)\n",
    "sk_y_pred = sklearn_rf.predict(X_test)\n",
    "end_time_sk = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of implementation:  0.23957197065958202\n",
      "RMSE of sklearn:  0.23670866714860314\n",
      "Runtime of implementation 118.94622135162354\n",
      "Runtime of sklearn 0.011986255645751953\n"
     ]
    }
   ],
   "source": [
    "implementation_rmse = root_mean_squared_error(y_test, y_pred)\n",
    "sklearn_rmse = root_mean_squared_error(y_test, sk_y_pred)\n",
    "print(\"RMSE of implementation: \", implementation_rmse)\n",
    "print(\"RMSE of sklearn: \", sklearn_rmse)\n",
    "implementation_runtime = end_time_implementation - start_time_implementation\n",
    "sklearn_runtime = end_time_sk - start_time_sk\n",
    "print(\"Runtime of implementation\", implementation_runtime)\n",
    "print(\"Runtime of sklearn\", sklearn_runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Increase min_sample_split to 10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_implementation = time.time()\n",
    "rf = RandomForestRegressor(n_trees=5, max_features=1, min_samples_split=10, max_depth=5)\n",
    "rf.train(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "end_time_implementation = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_sk = time.time()\n",
    "sklearn_rf = sklearn.ensemble.RandomForestRegressor(n_estimators=5, max_depth=5, max_features=1, min_samples_split=10, random_state=RANDOM_SEED)\n",
    "sklearn_rf.fit(X_train, y_train)\n",
    "sk_y_pred = sklearn_rf.predict(X_test)\n",
    "end_time_sk = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of implementation:  0.23971056926151618\n",
      "RMSE of sklearn:  0.2366636121308085\n",
      "Runtime of implementation 142.0025818347931\n",
      "Runtime of sklearn 0.009978532791137695\n"
     ]
    }
   ],
   "source": [
    "implementation_rmse = root_mean_squared_error(y_test, y_pred)\n",
    "sklearn_rmse = root_mean_squared_error(y_test, sk_y_pred)\n",
    "print(\"RMSE of implementation: \", implementation_rmse)\n",
    "print(\"RMSE of sklearn: \", sklearn_rmse)\n",
    "implementation_runtime = end_time_implementation - start_time_implementation\n",
    "sklearn_runtime = end_time_sk - start_time_sk\n",
    "print(\"Runtime of implementation\", implementation_runtime)\n",
    "print(\"Runtime of sklearn\", sklearn_runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments on number of trees\n",
    "**1. Increasing number of trees to 30**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_implementation = time.time()\n",
    "rf = RandomForestRegressor(n_trees=30, max_features=1, min_samples_split=2, max_depth=5)\n",
    "rf.train(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "end_time_implementation = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_sk = time.time()\n",
    "sklearn_rf = sklearn.ensemble.RandomForestRegressor(n_estimators=30, max_depth=5, max_features=1, min_samples_split=2, random_state=RANDOM_SEED)\n",
    "sklearn_rf.fit(X_train, y_train)\n",
    "sk_y_pred = sklearn_rf.predict(X_test)\n",
    "end_time_sk = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of implementation:  0.23897789683634196\n",
      "RMSE of sklearn:  0.2364491907196206\n",
      "Runtime of implementation 436.18719482421875\n",
      "Runtime of sklearn 0.033196210861206055\n"
     ]
    }
   ],
   "source": [
    "implementation_rmse = root_mean_squared_error(y_test, y_pred)\n",
    "sklearn_rmse = root_mean_squared_error(y_test, sk_y_pred)\n",
    "print(\"RMSE of implementation: \", implementation_rmse)\n",
    "print(\"RMSE of sklearn: \", sklearn_rmse)\n",
    "implementation_runtime = end_time_implementation - start_time_implementation\n",
    "sklearn_runtime = end_time_sk - start_time_sk\n",
    "print(\"Runtime of implementation\", implementation_runtime)\n",
    "print(\"Runtime of sklearn\", sklearn_runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Increasing number of trees to 100**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_implementation = time.time()\n",
    "rf = RandomForestRegressor(n_trees=100, max_features=1, min_samples_split=2, max_depth=5)\n",
    "rf.train(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "end_time_implementation = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_sk = time.time()\n",
    "sklearn_rf = sklearn.ensemble.RandomForestRegressor(n_estimators=100, max_depth=5, max_features=1, min_samples_split=2, random_state=RANDOM_SEED)\n",
    "sklearn_rf.fit(X_train, y_train)\n",
    "sk_y_pred = sklearn_rf.predict(X_test)\n",
    "end_time_sk = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of implementation:  0.2388503304319085\n",
      "RMSE of sklearn:  0.23623599489908745\n",
      "Runtime of implementation 1459.9423739910126\n",
      "Runtime of sklearn 0.09917593002319336\n"
     ]
    }
   ],
   "source": [
    "implementation_rmse = root_mean_squared_error(y_test, y_pred)\n",
    "sklearn_rmse = root_mean_squared_error(y_test, sk_y_pred)\n",
    "print(\"RMSE of implementation: \", implementation_rmse)\n",
    "print(\"RMSE of sklearn: \", sklearn_rmse)\n",
    "implementation_runtime = end_time_implementation - start_time_implementation\n",
    "sklearn_runtime = end_time_sk - start_time_sk\n",
    "print(\"Runtime of implementation\", implementation_runtime)\n",
    "print(\"Runtime of sklearn\", sklearn_runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment on default values with sklearn RandomForestRegressor for comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_sk = time.time()\n",
    "sklearn_rf = sklearn.ensemble.RandomForestRegressor(random_state=RANDOM_SEED)\n",
    "sklearn_rf.fit(X_train, y_train)\n",
    "sk_y_pred = sklearn_rf.predict(X_test)\n",
    "end_time_sk = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of sklearn:  0.26191354302456943\n",
      "Runtime of sklearn 4.385132074356079\n"
     ]
    }
   ],
   "source": [
    "sklearn_rmse = root_mean_squared_error(y_test, sk_y_pred)\n",
    "print(\"RMSE of sklearn: \", sklearn_rmse)\n",
    "sklearn_runtime = end_time_sk - start_time_sk\n",
    "print(\"Runtime of sklearn\", sklearn_runtime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
